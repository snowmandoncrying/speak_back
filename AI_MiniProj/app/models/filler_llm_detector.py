import os
import openai
import whisper
import torch
from dotenv import load_dotenv
from typing import Dict
import re
import json
import tempfile

# .env íŒŒì¼ì—ì„œ OPENAI_API_KEY ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ë§ë²„ë¦‡ ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸
FULL_TEXT_PROMPT = """ë‹¤ìŒì€ ë°œí‘œ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤. 'ìŒ', 'ì–´', 'ê·¸ë‹ˆê¹Œ', 'ì•„ë§ˆ', 'ê·¸ë˜ì„œ', 'ë­ëƒë©´', 'ì €ê¸°', 'ê·¸ê²Œ', 'ê·¸ëŸ¬ë‹ˆê¹Œ', 'ì•„', 'ë„¤', 'ì˜ˆ' ë“±ì˜ ë§ë²„ë¦‡ì´ í¬í•¨ëœ ë¬¸ì¥ë§Œ ê³¨ë¼ JSONìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”. ê° ë¬¸ì¥ì— ì–´ë–¤ ë§ë²„ë¦‡ì´ ëª‡ ë²ˆ ë“±ì¥í–ˆëŠ”ì§€ë„ í•¨ê»˜ í‘œì‹œí•´ì£¼ì„¸ìš”. 

ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:
[
  {{"ë¬¸ì¥": "ìŒ ì €í¬ëŠ” ì´ë²ˆì—...", "ë§ë²„ë¦‡": {{"ìŒ": 1}}}},
  {{"ë¬¸ì¥": "ê·¸ë‹ˆê¹Œ ì•„ë§ˆ...", "ë§ë²„ë¦‡": {{"ê·¸ë‹ˆê¹Œ": 1, "ì•„ë§ˆ": 1}}}}
]

í…ìŠ¤íŠ¸:
{text}"""

class FillerDetector:
    def __init__(self, model_size: str = "medium"):
        self.model_size = model_size
        self.model = None
        
    def _load_model(self):
        """Whisper ëª¨ë¸ì„ ì§€ì—° ë¡œë”©"""
        if self.model is None:
            device = "cuda" if torch.cuda.is_available() else "cpu"
            self.model = whisper.load_model(self.model_size, device=device)
    
    def analyze_filler_from_bytes(self, file_content: bytes, verbose: bool = False) -> Dict:
        """
        ìŒì„± íŒŒì¼ bytesì—ì„œ ë§ë²„ë¦‡ íƒì§€
        
        Args:
            file_content (bytes): ìŒì„± íŒŒì¼ bytes
            verbose (bool): ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
            
        Returns:
            Dict: ë¶„ì„ ê²°ê³¼
                {
                    "success": bool,
                    "full_text": str,
                    "filler_sentences": list,
                    "total_filler_counts": dict,
                    "total_fillers": int,
                    "total_sentences_with_fillers": int,
                    "error": str (ì—ëŸ¬ ë°œìƒì‹œ)
                }
        """
        # ì„ì‹œ íŒŒì¼ ìƒì„±
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
            temp_file.write(file_content)
            temp_file_path = temp_file.name
        
        try:
            if verbose:
                print("â³ Whisperë¡œ ë³€í™˜ ì¤‘...")
            
            # Whisper ëª¨ë¸ ë¡œë“œ
            self._load_model()
            
            # ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            result = self.model.transcribe(
                temp_file_path,
                language="ko",
                task="transcribe",
                verbose=False,
                temperature=0.0,
                beam_size=8,
                best_of=8,
                patience=1.5,
                length_penalty=0.8,
                no_speech_threshold=0.1,
                logprob_threshold=-3.0,
                condition_on_previous_text=False,
                suppress_tokens=[],
                word_timestamps=False,
                initial_prompt=(
                    "í•œêµ­ì–´ë¡œ ë§í•˜ëŠ” ìŒì„±ì…ë‹ˆë‹¤. "
                    "ìŒ, ì–´, ì•„, ìœ¼ìŒ, ì–´ì–´, ê·¸ë‹ˆê¹Œ, ì•„ë§ˆ, ê·¸ë˜ì„œ, ë­ëƒë©´, ì €ê¸°, ê·¸ê²Œ, ê·¸ëŸ¬ë‹ˆê¹Œ, ë„¤, ì˜ˆ, ì‘, í˜¹ì‹œ, ì¼ë‹¨ "
                    "ë“±ì˜ ëª¨ë“  ë§ë²„ë¦‡ê³¼ ê°íƒ„ì‚¬ë¥¼ ì ˆëŒ€ ìƒëµí•˜ì§€ ë§ê³  ë§í•œ ê·¸ëŒ€ë¡œ ì •í™•íˆ ì „ì‚¬í•˜ì„¸ìš”. "
                    "ì•„ì£¼ ì§§ì€ ë§ë²„ë¦‡ì´ë‚˜ ë¨¸ë­‡ê±°ë¦¼ë„ ëª¨ë‘ í¬í•¨í•´ì£¼ì„¸ìš”. "
                    "ì‹¬ì§€ì–´ 'ìŒ...', 'ì–´...', 'ì•„...' ê°™ì€ ì§§ì€ ê°íƒ„ì‚¬ë„ ë¹ ì§ì—†ì´ ì „ì‚¬í•˜ì„¸ìš”."
                )
            )
            
            full_text = result["text"]
            if verbose:
                print(f"âœ… Whisper ë³€í™˜ ì™„ë£Œ!")
                print(f"ğŸ¤– LLMìœ¼ë¡œ ë§ë²„ë¦‡ ë¬¸ì¥ ì¶”ì¶œ ì¤‘...")
            
            # OpenAI LLMìœ¼ë¡œ ë§ë²„ë¦‡ í¬í•¨ ë¬¸ì¥ ì¶”ì¶œ
            return self._extract_filler_sentences(full_text, verbose)
            
        except Exception as e:
            return {
                "success": False,
                "error": f"ìŒì„± ë³€í™˜ ì˜¤ë¥˜: {str(e)}",
                "full_text": "",
                "filler_sentences": [],
                "total_filler_counts": {},
                "total_fillers": 0,
                "total_sentences_with_fillers": 0
            }
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(temp_file_path)
    
    def _extract_filler_sentences(self, full_text: str, verbose: bool = False) -> Dict:
        """OpenAI LLMìœ¼ë¡œ ë§ë²„ë¦‡ í¬í•¨ ë¬¸ì¥ ì¶”ì¶œ"""
        prompt = FULL_TEXT_PROMPT.format(text=full_text)
        
        try:
            response = openai.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.0,
                max_tokens=2000
            )
            content = response.choices[0].message.content.strip()
            
            # JSON ì¶”ì¶œ ë° íŒŒì‹±
            match = re.search(r'\[.*\]', content, re.DOTALL)
            if match:
                json_str = match.group(0)
                filler_sentences = json.loads(json_str)
                
                # ì „ì²´ í†µê³„ ê³„ì‚°
                total_filler_counts = {}
                total_fillers = 0
                
                for sentence_data in filler_sentences:
                    if "ë§ë²„ë¦‡" in sentence_data:
                        for filler, count in sentence_data["ë§ë²„ë¦‡"].items():
                            total_filler_counts[filler] = total_filler_counts.get(filler, 0) + count
                            total_fillers += count
                
                if verbose:
                    print("âœ… ë§ë²„ë¦‡ ë¶„ì„ ì™„ë£Œ!")
                
                return {
                    "success": True,
                    "full_text": full_text,
                    "filler_sentences": filler_sentences,
                    "total_filler_counts": total_filler_counts,
                    "total_fillers": total_fillers,
                    "total_sentences_with_fillers": len(filler_sentences)
                }
            else:
                return {
                    "success": False,
                    "error": "LLM ì‘ë‹µì—ì„œ JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ",
                    "full_text": full_text,
                    "filler_sentences": [],
                    "total_filler_counts": {},
                    "total_fillers": 0,
                    "total_sentences_with_fillers": 0
                }
        
        except Exception as e:
            return {
                "success": False,
                "error": f"LLM ë¶„ì„ ì˜¤ë¥˜: {str(e)}",
                "full_text": full_text,
                "filler_sentences": [],
                "total_filler_counts": {},
                "total_fillers": 0,
                "total_sentences_with_fillers": 0
            }

# APIì—ì„œ ì‚¬ìš©í•  ê°„ë‹¨í•œ í•¨ìˆ˜
def analyze_filler_from_bytes(file_content: bytes, model_size: str = "medium", verbose: bool = False) -> Dict:
    """
    ê°„í¸í•œ ì‚¬ìš©ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜
    
    Args:
        file_content (bytes): ìŒì„± íŒŒì¼ bytes
        model_size (str): Whisper ëª¨ë¸ í¬ê¸°
        verbose (bool): ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
        
    Returns:
        Dict: ë¶„ì„ ê²°ê³¼
    """
    detector = FillerDetector(model_size)
    return detector.analyze_filler_from_bytes(file_content, verbose)

# ì¶œë ¥ìš© í•¨ìˆ˜ (ì„ íƒì ìœ¼ë¡œ ì‚¬ìš©)
def print_filler_results(result: Dict):
    """ë¶„ì„ ê²°ê³¼ë¥¼ ì½˜ì†”ì— ì˜ˆì˜ê²Œ ì¶œë ¥"""
    if not result["success"]:
        print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        return
    
    print("\n" + "="*70)
    print("ğŸ¯ ë§ë²„ë¦‡ ë¬¸ì¥ ì¶”ì¶œ ê²°ê³¼")
    print("="*70)
    
    print(f"ğŸ”¢ ì´ ë§ë²„ë¦‡ ìˆ˜: {result['total_fillers']}ê°œ")
    print(f"ğŸ“ ë§ë²„ë¦‡ í¬í•¨ ë¬¸ì¥ ìˆ˜: {result['total_sentences_with_fillers']}ê°œ")
    
    if result['total_filler_counts']:
        print(f"\nğŸ—£ï¸ ë§ë²„ë¦‡ë³„ í†µê³„:")
        for filler, count in sorted(result['total_filler_counts'].items(), 
                                   key=lambda x: x[1], reverse=True):
            percentage = round(count / result['total_fillers'] * 100, 1)
            print(f"  - {filler}: {count}íšŒ ({percentage}%)")
        
        print(f"\nğŸ“ ë§ë²„ë¦‡ í¬í•¨ ë¬¸ì¥:")
        print("-"*70)
        
        for i, sentence_data in enumerate(result['filler_sentences'], 1):
            print(f"\n[{i}] {sentence_data['ë¬¸ì¥']}")
            print(f"ë§ë²„ë¦‡: {sentence_data['ë§ë²„ë¦‡']}")
    else:
        print("\në§ë²„ë¦‡ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print("\n" + "="*70)
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print("="*70)

# í…ŒìŠ¤íŠ¸ìš© (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)
if __name__ == "__main__":
    # íŒŒì¼ ê²½ë¡œë¡œ í…ŒìŠ¤íŠ¸í•˜ëŠ” í•¨ìˆ˜
    def test_with_file(audio_file_path: str):
        from pathlib import Path
        
        if not Path(audio_file_path).exists():
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file_path}")
            return
        
        # íŒŒì¼ì„ bytesë¡œ ì½ì–´ì„œ í…ŒìŠ¤íŠ¸
        with open(audio_file_path, 'rb') as f:
            file_content = f.read()
        
        print("ğŸ” ë§ë²„ë¦‡ ë¬¸ì¥ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        result = analyze_filler_from_bytes(file_content, verbose=True)
        print_filler_results(result)
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    audio_file = "test_audio/b1055308.wav"
    test_with_file(audio_file)